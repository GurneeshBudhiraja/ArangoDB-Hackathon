{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs the Required Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pandas\n",
    "!pip install -U matplotlib\n",
    "!pip install -U python-dotenv\n",
    "\n",
    "!pip install nx-arangodb\n",
    "!pip install arango-datasets\n",
    "\n",
    "!pip install google-genai\n",
    "!pip install langchain-openai\n",
    "!pip install langchain-mistralai\n",
    "\n",
    "!pip install langchain\n",
    "!pip install langchain-google-genai\n",
    "!pip install -U langchain-community\n",
    "!pip install langgraph\n",
    "\n",
    "!pip install python-louvain\n",
    "!pip install tabulate\n",
    "!pip install folium\n",
    "!pip install ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports the packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import json\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, Dict, Tuple, Literal, Union, Any\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tabulate import tabulate\n",
    "import pprint\n",
    "import re\n",
    "import shutil\n",
    "from IPython.display import display, display_html\n",
    "import folium\n",
    "\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import nx_arangodb as nxadb\n",
    "from pathlib import Path  \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "from arango import ArangoClient\n",
    "from arango_datasets import Datasets\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.graphs import ArangoGraph\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.chains import ArangoGraphQAChain\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.tools import tool\n",
    "from langchain.chains import ArangoGraphQAChain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Gemini SDK Packages\n",
    "from google import genai\n",
    "\n",
    "# OpenAI SDK Packages\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads the env variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "ARANGO_HOST = os.environ[\"ARANGO_HOST\"]\n",
    "ARANGO_PASSWORD = os.environ[\"ARANGO_PASSWORD\"]\n",
    "ARANGO_USERNAME = os.environ[\"ARANGO_USERNAME\"]\n",
    "GEMINI_API = os.environ[\"GEMINI_API_KEY\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPEN_API_KEY\"]\n",
    "MISTRAL_API_KEY = os.environ[\"MISTRAL_API_KEY\"]\n",
    "LANGSMITH_TRACING=os.environ[\"LANGSMITH_TRACING\"]\n",
    "LANGSMITH_ENDPOINT=os.environ[\"LANGSMITH_ENDPOINT\"]\n",
    "LANGSMITH_API_KEY=os.environ[\"LANGSMITH_API_KEY\"]\n",
    "LANGSMITH_PROJECT=os.environ[\"LANGSMITH_PROJECT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the ArangoDB Connection, LLM Instance, and initializing the constants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ArangoDB Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arango_client = ArangoClient(hosts=ARANGO_HOST).db(username=ARANGO_USERNAME, password=ARANGO_PASSWORD, verify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gemini and OpenAI SDK Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_client = genai.Client(\n",
    "    api_key=GEMINI_API\n",
    ")\n",
    "\n",
    "openai_client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Names' Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini models\n",
    "GEMINI_FLASH_MODEL = \"gemini-2.0-flash\"\n",
    "GEMINI_FLASH_LITE_MODEL = \"gemini-2.0-flash-lite\"\n",
    "GEMINI_PRO_MODEL = \"gemini-1.5-pro\"\n",
    "\n",
    "# OpenAI Model\n",
    "GPT_4O = \"gpt-4o\"\n",
    "GPT_4O_MINI = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "# MistralAI Model\n",
    "MISTRAL_LARGE=\"mistral-large-latest\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionally loads the SYNTHEA_P100 dataset in ArangoDB and creates an ArangoGraph instance using ArangoDB instance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loads the dataset in ArangoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = Datasets(arango_client)\n",
    "\n",
    "DATASET_NAME = \"SYNTHEA_P100\"\n",
    "\n",
    "# Conditionally Loads the Synthea P100 dataset in Arango\n",
    "if not arango_client.has_graph(DATASET_NAME):\n",
    "  datasets.load(dataset_name=DATASET_NAME)\n",
    "else:\n",
    "  print(f\"{DATASET_NAME} is already in ArangoDB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creates an ArangoGraph instance using the Arango DB instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connects with the Graph in ArangoDB\n",
    "graph = None\n",
    "if arango_client.has_graph(DATASET_NAME):\n",
    "  graph = nxadb.Graph(name=\"SYNTHEA_P100\",db=arango_client)\n",
    "else:\n",
    "  print(\"Graph does not exist in Arango DB\")\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arango_graph = ArangoGraph(db=arango_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract graph schema and edge definitions from schema data\n",
    "graph_schema = arango_graph.schema[\"Graph Schema\"][0]\n",
    "edge_definitions = graph_schema[\"edge_definitions\"]\n",
    "\n",
    "\n",
    "# Create directed graph and add edges based on vertex collections\n",
    "G_schema = nx.DiGraph()\n",
    "for ed in edge_definitions:\n",
    "    edge_collection = ed[\"edge_collection\"]\n",
    "    from_list = ed[\"from_vertex_collections\"]\n",
    "    to_list = ed[\"to_vertex_collections\"]\n",
    "    for f in from_list:\n",
    "        for t in to_list:\n",
    "            G_schema.add_edge(f, t, label=edge_collection)\n",
    "\n",
    "\n",
    "# Set the layout for the graph visualization\n",
    "pos = nx.spring_layout(G_schema, k=2, seed=42)\n",
    "\n",
    "\n",
    "# Create figure with light blue background\n",
    "plt.figure(figsize=(20, 15), facecolor='#f0f8ff')\n",
    "\n",
    "\n",
    "# Draw nodes with color gradient\n",
    "node_colors = plt.cm.viridis(np.linspace(0, 1, len(G_schema.nodes())))\n",
    "nx.draw_networkx_nodes(\n",
    "    G_schema, pos,\n",
    "    node_size=2000,\n",
    "    node_color=node_colors,\n",
    "    edgecolors='navy',\n",
    "    linewidths=2.0,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "\n",
    "# Draw edges with color gradient and curved arrows\n",
    "edge_colors = plt.cm.coolwarm(np.linspace(0, 1, len(G_schema.edges())))\n",
    "nx.draw_networkx_edges(\n",
    "    G_schema, pos,\n",
    "    arrowstyle='fancy',\n",
    "    arrowsize=25,\n",
    "    edge_color=edge_colors,\n",
    "    width=2.5,\n",
    "    connectionstyle='arc3,rad=0.2',\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "\n",
    "# Add node labels with white background\n",
    "nx.draw_networkx_labels(\n",
    "    G_schema, pos,\n",
    "    font_size=14,\n",
    "    font_weight='bold',\n",
    "    bbox=dict(facecolor='white', edgecolor='none', alpha=0.7, pad=4)\n",
    ")\n",
    "\n",
    "\n",
    "# Add edge labels with white background\n",
    "edge_labels = nx.get_edge_attributes(G_schema, 'label')\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G_schema, pos,\n",
    "    edge_labels=edge_labels,\n",
    "    font_color='darkred',\n",
    "    font_size=12,\n",
    "    font_weight='bold',\n",
    "    bbox=dict(facecolor='white', edgecolor='none', alpha=0.7, pad=2)\n",
    ")\n",
    "\n",
    "plt.title(\"SYNTHEA_P100 Graph\", fontsize=24, pad=100)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table_message(text_list:List[str], headers: List[str] = [], tablefmt: str = \"orgtbl\")->None:\n",
    "  \"\"\"\n",
    "  Prints a formatted message in a table format using tabulate library\n",
    "  Parameters:\n",
    "    text_list: List of strings to be displayed in the table\n",
    "    headers: Optional list of column headers\n",
    "    tablefmt: Table format style (default is \"orgtbl\")\n",
    "  \"\"\"\n",
    "  print(tabulate([text_list],headers=headers,tablefmt=tablefmt))\n",
    "\n",
    "\n",
    "def print_agent_tool(tool_name:str):\n",
    "  # Get the terminal's width\n",
    "  terminal_width = shutil.get_terminal_size().columns\n",
    "\n",
    "  # Center the tool name and print it\n",
    "  centered_message = f\"{f'ü©∫ Using Tool: {tool_name}'.center(terminal_width)}\"\n",
    "  print(centered_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code and results from text_to_nx_algorithm_to_text\n",
    "text_to_nx_code = None\n",
    "text_to_nx_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def text_to_nx_algorithm_to_text(modified_query:str) -> Dict:\n",
    "    \"\"\"\n",
    "    This tool is available to invoke a NetworkX Algorithm on the ArangoDB Graph and also plot the graph.\n",
    "\n",
    "    Args:\n",
    "        modified_query: str = The modified query would be that version of initial user query that is free of typos and mistakes. The modified query is just a better constructed version of the initial query. The modified query should only contain the query that is related to networkX or any kind of visualisation. \n",
    "    \n",
    "    Returns:\n",
    "        Returns a python dictionary having keys `natural_language_response` and `graph_operation_result`. The `natural_language_response` contains natural language summary of the value of dictionary key `graph_operation_result` and shown to the user. \n",
    "        The `graph_operation_result` contains the data fetched after the graph operation.\n",
    "    \"\"\"\n",
    "    print_agent_tool(\n",
    "        tool_name=\"text_to_nx_algorithm_to_text\"\n",
    "    )\n",
    "    \n",
    "    model = ChatGoogleGenerativeAI(temperature=0, model=GEMINI_FLASH_MODEL, api_key=GEMINI_API)\n",
    "\n",
    "    print_table_message(\n",
    "        text_list=[\"\\n\".join(modified_query[i:i+90] for i in range(0, len(modified_query), 90))],\n",
    "        headers=[\"üîÑ Updated User Query\"],\n",
    "        tablefmt=\"rounded_grid\",\n",
    "    )\n",
    "\n",
    "\n",
    "    print_table_message(\n",
    "        text_list=[\"‚öôÔ∏è Generating NetworkX Algorithm... Please wait ‚è≥\"],\n",
    "        headers=[],\n",
    "        tablefmt=\"outline\"\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    unformatted_code = model.invoke(f\"\"\"\n",
    "    I have a NetworkX Graph called `graph`. It has the following schema: {arango_graph.schema}\n",
    "\n",
    "    I have the following graph analysis query: {modified_query}.\n",
    "\n",
    "    Generate the Python Code required to answer the query using the `graph` object.\n",
    "\n",
    "    Also, whenever mentioned generate the Python code for visualising the outputs. Please make sure to include that code with the other Python code. Only generate the visualisation code when explicitly mentioned in the query. Keep in mind, that for the visualisation code, no need to use all the dataset from the graph since that would be computational expensive and would slow down the overall operation. Make sure the visualisation looks modern, use different ways to distinguish the entities, and always use the colors that are good for the light theme. Do not plot something that has not been asked.\n",
    "\n",
    "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
    "\n",
    "    Only assume that networkx is installed, and other base python dependencies.\n",
    "\n",
    "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
    "\n",
    "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
    "\n",
    "    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
    "\n",
    "    Your code:\n",
    "    \"\"\").content\n",
    "    \n",
    "    # Extracting the code\n",
    "    cleaned_code = re.sub(r\"^```python\\n|```$\", \"\", unformatted_code, flags=re.MULTILINE).strip()\n",
    "    \n",
    "    # Printing the formatted code\n",
    "    print_table_message(    \n",
    "        text_list=[cleaned_code],\n",
    "        headers=[\"üìù Generated NetworkX Algorithm\"],\n",
    "        tablefmt=\"rounded_grid\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print_table_message(\n",
    "        text_list=[\"üîç Executing the NetworkX Algorithm... Please wait ‚è≥\"],\n",
    "        headers=[],\n",
    "        tablefmt=\"outline\"\n",
    "    )\n",
    "\n",
    "    global_vars = {\n",
    "        \"graph\":graph,\n",
    "        \"nx\":nx\n",
    "    }\n",
    "\n",
    "    local_vars = {}\n",
    "    try:    \n",
    "        exec(cleaned_code, global_vars, local_vars)\n",
    "        # Copy the code that worked\n",
    "        cleaned_code_copy = cleaned_code\n",
    "    except Exception as e:\n",
    "        print(\"\\n\")\n",
    "        print_table_message(\n",
    "            text_list=[f\"‚ö†Ô∏è Error: Failed to Execute the Original NetworkX Algorithm.\"],\n",
    "            headers=[],\n",
    "            tablefmt=\"plain\"\n",
    "        )\n",
    "\n",
    "        total_tries = 5\n",
    "        while True:\n",
    "            # Out of total_tries\n",
    "            if(total_tries == 0):\n",
    "                print(\"\\n\")\n",
    "                print_table_message(\n",
    "                    text_list=[f\"‚ùå Failed to Resolve the NetworkX Algorithm after multiple attempts.\"],\n",
    "                    headers=[],\n",
    "                    tablefmt=\"heavy_outline\"\n",
    "                )\n",
    "                return\n",
    "            \n",
    "            print(\"\\n\")\n",
    "            print_table_message(\n",
    "                text_list=[f\"‚ùå Fixing the NetworkX Algorithm... {total_tries} Attempts Remaining.\"],\n",
    "                headers=[],\n",
    "                tablefmt=\"grid\"\n",
    "            )\n",
    "\n",
    "            total_tries -= 1\n",
    "\n",
    "            unformatted_corrected_code = model.invoke(f\"\"\"\n",
    "                I have a NetworkX Graph called `graph`. It has the following schema: {arango_graph.schema}\n",
    "\n",
    "                I have the following graph analysis query: {modified_query}.\n",
    "                \n",
    "                This is the python code that has been executed to do the graph analysis of the query.\n",
    "                \n",
    "                -------- <python_code> --------\n",
    "                    {cleaned_code}\n",
    "                -------- </python_code> --------\n",
    "                \n",
    "                And while executing the above Python code this is the error that has been encountered\n",
    "                -------- <error> --------\n",
    "                {e}\n",
    "                -------- </error> --------\n",
    "                Think step by step.\n",
    "                \n",
    "                General Instructions: \n",
    "                    Look for the wrong variable names. The NetworkX graph is called `graph` and networkX library has been imported like this `import networkx as nx`. \n",
    "\n",
    "                    Look for the wrong mention of collections, edges, attributes, field or any other name/variable that is not in the graph schema. \n",
    "                    \n",
    "                    Look if the code has mistakes related to the graph plotting. \n",
    "\n",
    "                    Check for the import errors.\n",
    "\n",
    "                    Please make sure to properly go through the error, python code provided, schema and other information before you give the corrected code. \n",
    "                    \n",
    "                    While solving the bug/error, it is important to take gaps for you to think properly.\n",
    "\n",
    "                    In the new code only add the required comments and anything without the comments should not be added as this code would be taken as it is to be executed.\n",
    "\n",
    "                    Only assume that networkx is installed, and other base python dependencies.\n",
    "\n",
    "                    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
    "\n",
    "                    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
    "\n",
    "                    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
    "\n",
    "                    In the new code only add the required comments and anything without the comments should not be added as this code would be taken as it is to be executed. Only return the corrected code in front of `Your code:` that is mentioned below:\n",
    "                    Your code:\n",
    "                \"\"\").content\n",
    "            \n",
    "            formatted_corrected_code = re.sub(r\"^```python\\n|```$\", \"\", unformatted_corrected_code, flags=re.MULTILINE).strip()\n",
    "\n",
    "            # Shows the corrected code\n",
    "            print_table_message(\n",
    "                text_list=[formatted_corrected_code],\n",
    "                headers=[\"üîß Corrected NetworkX Algorithm\"],\n",
    "                tablefmt=\"rounded_grid\"\n",
    "            )\n",
    "\n",
    "\n",
    "            print(\"\\n\")\n",
    "            print_table_message(\n",
    "                text_list=[\"‚öôÔ∏è Executing the Corrected NetworkX Algorithm... Please wait ‚è≥\"],\n",
    "                headers=[],\n",
    "                tablefmt=\"outline\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                exec(formatted_corrected_code, global_vars, local_vars)\n",
    "                cleaned_code_copy = formatted_corrected_code\n",
    "                break\n",
    "            except:\n",
    "                print(\"\\n\")\n",
    "                print_table_message(\n",
    "                    text_list=[f\"‚ö†Ô∏è Error: Failed to Execute the Corrected NetworkX Algorithm.\"],\n",
    "                    headers=[],\n",
    "                    tablefmt=\"fancy_grid\" \n",
    "                )\n",
    "\n",
    "                continue\n",
    "\n",
    "    print_table_message(\n",
    "        text_list=[f\"‚úÖ Successfully executed the NetworkX Algorithm\"],\n",
    "        headers=[],\n",
    "        tablefmt=\"outline\"\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "\n",
    "    nx_code_final_result = local_vars[\"FINAL_RESULT\"]\n",
    "    \n",
    "    print_table_message(\n",
    "        text_list=[nx_code_final_result],\n",
    "        headers=[\"üíª NetworkX Algorithm Output\"],\n",
    "        tablefmt=\"rounded_grid\"\n",
    "    )\n",
    "\n",
    "    global text_to_nx_code, text_to_nx_results\n",
    "    text_to_nx_code = cleaned_code_copy\n",
    "    text_to_nx_results = nx_code_final_result\n",
    "    \n",
    "\n",
    "    natural_language_response = model.invoke(f\"\"\"\n",
    "        I have a NetworkX Graph called `graph`. It has the following schema: {arango_graph.schema}\n",
    "\n",
    "        I have the following graph analysis query: {modified_query}.\n",
    "\n",
    "        I have executed the following python code to help me answer my query:\n",
    "\n",
    "        ---\n",
    "        {cleaned_code_copy}\n",
    "        ---\n",
    "\n",
    "        The `FINAL_RESULT` variable is set to the following: {nx_code_final_result}.\n",
    "\n",
    "        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n",
    "        answer my query.\n",
    "\n",
    "        Your response:\n",
    "    \"\"\").content\n",
    "\n",
    "    print_table_message(\n",
    "        text_list=[\"\\n\".join(natural_language_response[i:i+80] for i in range(0, len(natural_language_response), 80))],\n",
    "        headers=[f\"üîç Answer to User Query\"],\n",
    "        tablefmt=\"rounded_grid\"\n",
    "    )\n",
    "    return {\n",
    "        \"natural_language_response\": natural_language_response,\n",
    "        \"graph_operation_result\": nx_code_final_result\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def text_to_aql_to_text(query:str):\n",
    "    \"\"\"\n",
    "    The tool is used to generate and return the results after applying the AQL on the SYNTHEA_P100 dataset. Modify the query to send that part from the initial user query for which AQL operation is required.\n",
    "\n",
    "    Args: \n",
    "    query: str = The natural language query that would be used to convert to AQL queries and then return the result.\n",
    "\n",
    "    Returns:\n",
    "    Returns the string of AQL response containing information about the asked query\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print_agent_tool(\n",
    "            tool_name=\"text_to_aql\"\n",
    "        )\n",
    "\n",
    "        print_table_message(\n",
    "        text_list=[\"\\n\".join(query[i:i+80] for i in range(0, len(query), 80))],\n",
    "        headers=[\"üîç Query Received in AQL Tool\"],\n",
    "        tablefmt=\"fancy_grid\"\n",
    "        )\n",
    "\n",
    "        aql_llm = ChatGoogleGenerativeAI(\n",
    "            model=GEMINI_FLASH_LITE_MODEL,\n",
    "            api_key=GEMINI_API,\n",
    "            temperature=0.2,\n",
    "        )\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print_table_message(\n",
    "            text_list=[\"üöÄ Running the ArangoGraphQAChain\"]\n",
    "        )\n",
    "        chain = ArangoGraphQAChain.from_llm(\n",
    "            llm=aql_llm, \n",
    "            graph=arango_graph, \n",
    "            verbose=True,\n",
    "            allow_dangerous_requests=True,\n",
    "            )\n",
    "        chain.return_aql_result = True\n",
    "        aql_chain_response = chain.invoke([HumanMessage(content=query)])\n",
    "        aql_result = aql_chain_response [\"aql_result\"]\n",
    "        aql_summary = chain.invoke([HumanMessage(content=query)])[\"result\"]\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print_table_message(\n",
    "            text_list=[\"\\n\".join(aql_summary[i:i+80] for i in range(0, len(aql_summary), 80))],\n",
    "            headers=[\"üîç AQL Response\"],\n",
    "            tablefmt=\"rounded_grid\"\n",
    "        )\n",
    "\n",
    "        return aql_result\n",
    "    except Exception as e:\n",
    "        print_table_message(\n",
    "            text_list=[\"Error in text_to_aql_to_text.\"],\n",
    "            headers=[\"‚ö†Ô∏è Error\"],\n",
    "            tablefmt=\"heavy_grid\"\n",
    "        )\n",
    "\n",
    "        return f\"This is the error that has occured in the `text_to_aql_to_text` tool: \\n{e}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def plot_coordinates_on_map(coordinates, map_center=None, zoom_start=12) -> None:\n",
    "    \"\"\"\n",
    "    Plots a list of coordinates on an interactive map with customizable marker colors and tags.\n",
    "\n",
    "    Parameters:\n",
    "        - coordinates: List of dictionaries with keys:\n",
    "            'lat' (float): Latitude.\n",
    "            'lon' (float): Longitude.\n",
    "            'tag' (str, optional): A label or popup text for the marker.\n",
    "            'marker_color' (str, optional): Color for the marker (default is 'blue').\n",
    "        - map_center: Optional tuple (lat, lon) to center the map. If not provided, center is calculated.\n",
    "        - zoom_start: Initial zoom level of the map.\n",
    "\n",
    "    Returns:\n",
    "        - None. The map is displayed immediately in the Jupyter Notebook.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print_agent_tool(tool_name=\"plot_coordinates_on_map\")\n",
    "\n",
    "        if not coordinates:\n",
    "            print(\"\\n\")\n",
    "            print_table_message(\n",
    "                text_list=[\"‚ö†Ô∏è Missing coordinates. \"],\n",
    "                headers=[\"‚ùå Missing Tool Parameters\"],\n",
    "                tablefmt=\"fancy_grid\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "        # Conditionally calculate the map center\n",
    "        if map_center is None:\n",
    "            avg_lat = sum(coord['lat'] for coord in coordinates) / len(coordinates)\n",
    "            avg_lon = sum(coord['lon'] for coord in coordinates) / len(coordinates)\n",
    "            map_center = (avg_lat, avg_lon)\n",
    "\n",
    "        # Create the Folium map\n",
    "        m = folium.Map(location=map_center, zoom_start=zoom_start)\n",
    "\n",
    "        # Add a marker for each coordinate with a custom color and tag\n",
    "        for coord in coordinates:\n",
    "            lat = coord['lat']\n",
    "            lon = coord['lon']\n",
    "            tag = coord.get('tag', '')\n",
    "            marker_color = coord.get('marker_color', 'blue')\n",
    "            folium.Marker(\n",
    "                location=(lat, lon),\n",
    "                popup=tag,\n",
    "                icon=folium.Icon(color=marker_color)\n",
    "            ).add_to(m)\n",
    "\n",
    "        # Display the map\n",
    "        display(m)\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print_table_message(\n",
    "            text_list=[\"Error in plot_coordinates_on_map.\"],\n",
    "            headers=[\"‚ö†Ô∏è Error\"],\n",
    "            tablefmt=\"heavy_grid\"\n",
    "        )\n",
    "\n",
    "        return f\"This is the error that has occured in the `plot_coordinates_on_map` tool: \\n{e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent executor function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(user_query:str):\n",
    "  \"\"\"\n",
    "    The function to call for the networkX agent.\n",
    "  \"\"\"\n",
    "  networkx_agent_tools = [text_to_nx_algorithm_to_text, text_to_aql_to_text, plot_coordinates_on_map]\n",
    "  networkx_agent_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=GPT_4O,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    verbose=True\n",
    "  )\n",
    "  \n",
    "  agent_prompt = \"\"\"\n",
    "      You are the helpful networkX agent who has access to multiple tools. Below are the tools that you have access to with their role:\n",
    "        1. `text_to_nx_algorithm_to_text`: This is the tool that would receive the modified version of the user query formatted and modified for the other LLM to properly understand. By modified query I do not mean to trim any part related to networkX or visulisation from the initial user query rather fix the typos and construct the query properly for the LLM to understand properly. The main and only function of this tool is to use AI to generate, implement, and show the results of the networkX algorithm to the user. The tool can also be used for the visualisation as this tool knows how to generate the code for the same. To summarize, this tool is used firstly to generate, execute and get the results from the graph(networkX) algorithms and can also handle requests that are related to visulisation, or plotting of the query related to only and only SYNTHEA_P100 dataset.\n",
    "\n",
    "        2. `text_to_aql_to_text`: This is the tool that is specialised in taking in the queries and use the LLM to convert those queries into the AQL queries, fetches the result by executing the queries and return the reponse in the natural language. The tool can be used to perform AQL operations on SYNTHEA_P100 dataset stored in ArangoDB. Make sure that the output from this tool should be able to help the user and get all the information that the user is looking for. If you think the information does not match with the intent of the user query, use this tool by tweaking the initial user query to get the desired results. To summarize this tool is used to find information that are best to be find using the AQL.\n",
    "\n",
    "        3. `plot_coordinates_on_map`: This is the tool that is uses the coordinates and plots them on the graph. You are free to use whenever you feel is the right time to use to enhance user experience. Please make sure to only use this tool once during the lifecycle. Also, only run this tool when you are completely sure that you have all the data for this tool or when the user has mentioned somewhere in the query. \n",
    "\n",
    "          Make sure the tags that have been passed in the coordinates dictionary should not just show the name of the entity but would also, show the a short description that would help the user know in what way the place is related to the patient. Keep this short and concise while making sure you mention the information.\n",
    "          \n",
    "          Thumb rule for using this tool is if you have coordinates, plot the map. You are also free to extract the data using other tools if required to plot the graph. Few places where you can do so and should do it are: \n",
    "          \n",
    "          1. When the user wants a summary of the patient data.\n",
    "          \n",
    "          2. User wants to know information about an entity in a collection and that collection has available data for you to plot the graph. \n",
    "          \n",
    "          3. You can also use this tool when the user has mentioned or inquired about any entity's location. You are free to experiment with this tool as long as it enhances the UX and UI. You are also allowed to get the coordinates and try if you can get some coordinates that would enhance the output of the overall user experience by plotting the graph. \n",
    "\n",
    "          4. If the user is asking about detailed/brief summary of a patient or related entities.\n",
    "\n",
    "          5. If the user has asked info about the user's location for which the complete coordinates are present in the database.\n",
    "          \n",
    "          Make sure that any output you receive in this tool would only be used to plot the graphs and not to be used to include in the final answer. \n",
    "          \n",
    "          Additionally, plot the data in such a way that each pointer looks visibly different from the other. \n",
    "          \n",
    "          For this you can add different colors for each marker and only select the color that are available in this dictionary: \n",
    "          <colors_to_choose_from>\n",
    "            {'pink', 'lightgray', 'blue', 'darkgreen', 'red', 'purple', 'green', 'darkred', 'cadetblue', 'lightgreen', 'gray', 'black', 'lightred', 'lightblue', 'white', 'beige', 'orange', 'darkblue', 'darkpurple'}\n",
    "          </colors_to_choose_from>\n",
    "\n",
    "      As of now you only have aforementioned tools, but more tools would be added later on. Do not run more than one tool at a time. At the end, if you are unable to fulfil any part of the user request, you can reply about that at the end. \n",
    "\n",
    "      Keep the tone natural and do not mention any apologetic/thankful messages. \n",
    "      \n",
    "      Properly analyse the sequence of tool to run. \n",
    "\n",
    "      There would be cases where you need to run all the tools to reach to the final answer, so carefully examine the tools and their sequence.\n",
    "\n",
    "      You are free to run single more than once to reach to the final and correct answer. \n",
    "\n",
    "      Before giving the end response, analyse the steps taken and the answer.\n",
    "\n",
    "      Do not end your response with an open ended question unless it is very required. \n",
    "      \n",
    "      Do not run more than one tool at once. Wait for the response from one tool before proceeding to the next tool.\n",
    "\n",
    "      You are free to modify the query that you pass to each tool. This would enhance the efficiency and would reduce the chances of wrong repsonses from each tool. \n",
    "\n",
    "      Take time and pauses to think and analyse before using the tools, or giving the output to the user query.\n",
    "\n",
    "      Do not mention about the tools you used during the process.\n",
    "      \n",
    "      Take gaps and proper time to properly use the tools. \n",
    "\n",
    "      If you get any queries that are not relevant to SYNTHEA_P100 dataset stored in ArangoDB or that can not be solved using networkX/graph algorithms then in that case you would politely deny the request.\n",
    "\n",
    "      At the end, combine all the responses from the tools and answer the initial user query in the natural neutral tone. \n",
    "    \"\"\"\n",
    "  agent_executor = create_react_agent(\n",
    "    tools=networkx_agent_tools,\n",
    "    model=networkx_agent_llm, \n",
    "    prompt=agent_prompt,\n",
    "  )\n",
    "  networkX_agent_response = (agent_executor.invoke({\"messages\":[HumanMessage(content=user_query)]}))[\"messages\"][-1].content\n",
    "  print(\"\\n\")\n",
    "  print_table_message(\n",
    "    text_list=[\"\\n\".join(networkX_agent_response[i:i+90] for i in range(0, len(networkX_agent_response), 90))],\n",
    "    headers=[\"üîç Final Agent Response\"],\n",
    "    tablefmt=\"double_grid\"\n",
    "  )\n",
    "  print(\"\\n\")\n",
    "  return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application's starter and helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(user_query:str):\n",
    "\n",
    "  # MainSchema Class\n",
    "  class MainSchema(BaseModel):\n",
    "    # Type of the agent\n",
    "    agent_type: str = Field(description=\"\"\"The type of agent to be used to answer the user query. You can either choose `aql`, `networkX` or `hybrid`. If the user query best needs to be solved using AQL then select `aql`, if the user query needs to use networkX algorithms then use `networkX`, and if the user query needs a combination of both networkX and AQL then select `hybrid`. Please also note that if the user has mentioned anything about the visulaisation, plotting of the graph, or anything that involves some kind of visualisation, you will ignore that part of the query and then select the best method. It is because each of the specialised agent has their own visualisaion tool. Any other queries that are not related to the SYNTHEA_P100 dataset in the ArangoDB and also that can not be solved using `aql`, `networkX`, or `hybrid` specialised agents are considered irrelevant.\"\"\", default=\"\")\n",
    "\n",
    "    # The reason for selecting a specific agent type\n",
    "    agent_type_reason: str = Field(description=\"The reason for the agent type. Please make sure to keep it short while informative for the end user.\", default=\"\")\n",
    "\n",
    "    # Check the relevancy of the message\n",
    "    is_relevant: bool = Field(description=\"If the user query is relevant to the dataset stored in ArangoDB then reply with True otherwise reply with False.\", default=False)\n",
    "\n",
    "    # When the message is not relevant\n",
    "    irrelevant_message_response:str =  Field(description=\"Keep the tone neutral and tell in a simple short sentence your main purpose. No need to mention any apologies or open ended questions in your response.\", default=\"\")\n",
    "\n",
    "  # LLM Parser\n",
    "  main_parser = JsonOutputParser(pydantic_object=MainSchema)  \n",
    "  \n",
    "  # LLM Prompt\n",
    "  main_prompt = PromptTemplate(\n",
    "    template=\"You are working with the SYNTHEA_P100 dataset stored in ArangoDB and based on the user query your main job is to tell what would be the right agent to go for the following user query. Should I find answer to the user's problem through aql, networkX, or hybrid. Please make sure that if the user query is not related to the SYNTHEA_P100 dataset stored in ArangoDB then you can deny the request and give a short message to the user. Please answer the question in this format {format_instructions} .This is the user_query: {user_query}.\",\n",
    "    input_variables=[\"user_query\"],\n",
    "    partial_variables={\"format_instructions\": main_parser.get_format_instructions()},\n",
    "  )\n",
    "\n",
    "\n",
    "  # LLM\n",
    "  main_model = ChatGoogleGenerativeAI(\n",
    "    model=GEMINI_FLASH_MODEL,\n",
    "    api_key=GEMINI_API,\n",
    "    temperature=0.1,\n",
    "    verbose=True\n",
    "  )\n",
    "\n",
    "  try:\n",
    "    # LangChain LCEL Chain\n",
    "    main_chain = main_prompt | main_model | main_parser \n",
    "    main_chain_response = main_chain.invoke({\"user_query\":user_query})\n",
    "    \n",
    "    return main_chain_response\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    return \"Something went wrong. Please try again later.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function of the main function\n",
    "def main_wrapper():\n",
    "  try:\n",
    "    user_query = \"\"\n",
    "\n",
    "    while not user_query: \n",
    "      user_query = input(\"Enter the user query: \").strip()\n",
    "\n",
    "    response = main(user_query=user_query)\n",
    "    \n",
    "    print_table_message(\n",
    "    text_list=[\"\\n\".join([user_query[i:i+80] for i in range(0, len(user_query), 80)])],\n",
    "    headers=[\"üë®‚Äçüíª User Query\"],\n",
    "    tablefmt=\"rounded_grid\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    agent_selection = (response[\"agent_type\"])\n",
    "    agent_selection_reason = response[\"agent_type_reason\"]\n",
    "    is_relevant = response[\"is_relevant\"]\n",
    "    irrelevant_message_response = response[\"irrelevant_message_response\"]\n",
    "\n",
    "    \n",
    "    # Checks for the irrelvant message\n",
    "    if not is_relevant:\n",
    "      print_table_message(\n",
    "        text_list=[\"\\n\".join([irrelevant_message_response[i:i+80] for i in range(0, len(irrelevant_message_response), 80)])],\n",
    "        headers=[\"üö® Irrelevant Message Response\"],\n",
    "        tablefmt=\"rounded_grid\"\n",
    "      )\n",
    "      return\n",
    "\n",
    "    # Shows the agent selection and the reason for the selection\n",
    "    print_table_message(\n",
    "      text_list=[agent_selection,\"\\n\".join([agent_selection_reason[i:i+80] for i in range(0, len(agent_selection_reason), 80)])],\n",
    "      headers=[\"ü§ñ Query Type\", \"üí° Reason\"],\n",
    "      tablefmt=\"rounded_grid\"\n",
    "    )\n",
    "\n",
    "    match agent_selection:\n",
    "      case \"aql\" | \"hybrid\" | \"networkX\":\n",
    "        agent(user_query=user_query)\n",
    "\n",
    "      case _:\n",
    "        print_table_message(\n",
    "          text_list=[\"üö® Unhandled case detected. Please try again with a different query. üîÑ\"],\n",
    "          headers=[],\n",
    "          tablefmt=\"heavy_grid\" \n",
    "        )\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    print_table_message(\n",
    "      text_list=[\"Something went wrong.\"],\n",
    "      headers=[\"Error üö©\"],\n",
    "      tablefmt=\"heavy_grid\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function that starts the execution of the whole program\n",
    "main_wrapper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arango-hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
